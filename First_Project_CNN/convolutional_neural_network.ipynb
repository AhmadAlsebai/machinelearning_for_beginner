{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf  # TensorFlow for deep learning\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Keras module for image preprocessing"
      ],
      "metadata": {
        "id": "vi1WU6nR8dTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cYHhur6E8dW4",
        "outputId": "6c61c42e-3058-41eb-fc18-a80c143c8711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.18.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,         # Normalize pixel values to a range of [0,1] (originally [0,255])\n",
        "        shear_range=0.2,        # Apply random shearing transformation to the images\n",
        "        zoom_range=0.2,         # Apply random zooming to images\n",
        "        horizontal_flip=True,   # Enable random horizontal flipping of images\n",
        "        fill_mode='nearest'     # Fill in missing pixels after transformations with the nearest pixel value\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'data/train',        # Path to the directory containing training images\n",
        "        target_size=(64, 64),  # Resize all images to 150x150 pixels\n",
        "        batch_size=32,       # Number of images to be processed in each batch\n",
        "        class_mode='binary'  # Binary classification (e.g., cats vs. dogs), suitable for binary_crossentropy loss\n",
        ")\n"
      ],
      "metadata": {
        "id": "QrJppz8sTpIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "# this is a similar generator, for validation data\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        'data/test_set',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "metadata": {
        "id": "m5wzZLXX_F0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "__qzj-XnE1Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a Convolutional Layer to the CNN\n",
        "cnn.add(tf.keras.layers.Conv2D(\n",
        "    filters=32,          # Number of filters (kernels), defining how many feature maps will be learned\n",
        "    kernel_size=3,       # Size of each filter (3x3 in this case), determining the receptive field\n",
        "    activation='relu',   # Activation function used to introduce non-linearity and prevent vanishing gradients\n",
        "    input_shape=[64, 64, 3]  # Shape of the input image: 64x64 pixels with 3 color channels (RGB)\n",
        "))"
      ],
      "metadata": {
        "id": "mHFLocxeE8Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a Max Pooling Layer to the CNN\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(\n",
        "    pool_size=(2, 2),  # Size of the pooling window (2x2), reducing spatial dimensions by taking the max value in each window\n",
        "    strides=2          # Step size for moving the pooling window, effectively downsampling the feature map\n",
        "))"
      ],
      "metadata": {
        "id": "5-7L6qCUwW7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(\n",
        "    filters=32,          # Number of filters (kernels), defining how many feature maps will be learned\n",
        "    kernel_size=3,       # Size of each filter (3x3 in this case), determining the receptive field\n",
        "    activation='relu',   # Activation function used to introduce non-linearity and prevent vanishing gradients\n",
        "    #input_shape=[64, 64, 3]  # Shape of the input image: 64x64 pixels with 3 color channels (RGB) only for first layer\n",
        "))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))"
      ],
      "metadata": {
        "id": "bsyS8pxex4g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flattening the feature maps into a 1D vector\n",
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "ObvTkx0tyRyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a Fully Connected (Dense) Layer to the CNN\n",
        "cnn.add(tf.keras.layers.Dense(\n",
        "    units=128,        # Number of neurons in this layer, controlling the learning capacity\n",
        "    activation='relu' # Activation function, introducing non-linearity and improving learning of complex patterns\n",
        "))"
      ],
      "metadata": {
        "id": "Xf-5ictMz4iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Step 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the Output Layer to the CNN\n",
        "cnn.add(tf.keras.layers.Dense(\n",
        "    units=1,         # Number of output neurons; 1 neuron for binary classification (e.g., cat vs. dog)\n",
        "    activation='sigmoid'  # Sigmoid activation function to output a probability between 0 and 1\n",
        "))"
      ],
      "metadata": {
        "id": "NOP-bvRt0RnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the CNN model\n",
        "cnn.compile(\n",
        "    optimizer='adam',              # Optimizer used to update weights efficiently (Adam is widely used for deep learning)\n",
        "    loss='binary_crossentropy',    # Loss function for binary classification (use 'categorical_crossentropy' for multi-class)\n",
        "    metrics=['accuracy']           # Metric to evaluate model performance (accuracy is commonly used for classification)\n",
        ")"
      ],
      "metadata": {
        "id": "922RgMa01Oyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Defining an Early Stopping callback\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',          # Monitors the validation loss during training\n",
        "    patience=7,                  # Stops training if validation loss doesn't improve for 5 consecutive epochs\n",
        "    restore_best_weights=True    # Restores the model's best weights before stopping\n",
        ")"
      ],
      "metadata": {
        "id": "UXyiN8hfC1rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the CNN model\n",
        "cnn.fit(\n",
        "    x=train_generator,        # Training dataset (augmented images from the data generator)\n",
        "    validation_data=test_set, # Validation dataset to monitor model performance\n",
        "    epochs=25,                # Number of complete passes over the entire training dataset\n",
        "    callbacks=[early_stop]    # Uses EarlyStopping to stop training if no improvement in validation loss\n",
        ")"
      ],
      "metadata": {
        "id": "ga07-d8-1R6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Loading and preprocessing the test image\n",
        "test_image = image.load_img(\n",
        "    'data/single_prediction/cat_or_dog_1.jpg',  # Path to the image to be tested\n",
        "    target_size=(64, 64)  # Resizing the image to match the CNN input shape\n",
        ")\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "# Making a prediction using the trained CNN\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "AtIh2MVq1SzP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}